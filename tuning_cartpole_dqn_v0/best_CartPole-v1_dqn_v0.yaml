model_kwargs:
  learning_rate: 0.0003
  gamma: 0.98
  buffer_size: 100000
  batch_size: 128
  learning_starts: 10000
  target_update_interval: 500
  exploration_fraction: 0.2
  exploration_final_eps: 0.02
  train_freq: 4
  gradient_steps: 1
  policy_kwargs:
    net_arch:
    - 256
    - 256
    activation_fn: Tanh

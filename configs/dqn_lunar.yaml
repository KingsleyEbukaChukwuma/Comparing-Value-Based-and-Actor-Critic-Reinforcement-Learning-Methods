model_kwargs:
  learning_rate: 0.0003
  gamma: 0.99
  buffer_size: 200000
  batch_size: 128
  learning_starts: 10000
  train_freq: 4
  gradient_steps: 1
  target_update_interval: 5000
  exploration_fraction: 0.40
  exploration_final_eps: 0.10
  policy_kwargs:
    net_arch: [256, 256]
    activation_fn: ReLU

model_kwargs: {}

policy_kwargs_space:
  net_arch:
    - [64, 64]
    - [128, 128]
    - [256, 256]
  activation_fn: ["ReLU", "Tanh"]

dqn_space:
  learning_rate: [0.001, 0.0005, 0.0003, 0.0001]
  gamma: [0.97, 0.99]
  buffer_size: [50000, 100000, 200000]
  batch_size: [64, 128]
  learning_starts: [1000, 5000, 10000]
  target_update_interval: [1000, 5000, 10000]
  exploration_fraction: [0.3, 0.4, 0.5]
  exploration_final_eps: [0.05, 0.10]

ppo_space:
  learning_rate: [0.0003, 0.00025, 0.0002]
  gamma: [0.99]
  n_steps: [512, 1024, 2048]
  batch_size: [64, 128, 256]
  n_epochs: [5, 10]
  clip_range: [0.2, 0.25]
  ent_coef: [0.0, 0.01, 0.02]
  gae_lambda: [0.90, 0.95, 0.98]
  vf_coef: [0.5, 0.7]
